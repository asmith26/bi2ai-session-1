{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Science in Python == Data Science in Numpy <img src=\"logo.png\",width=140,height=140, align=\"right\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The fundamental library for data science is numpy. __Numpy__ gives us *fast* and *powerful* tools for numerical operations on large, multi-dimensional arrays of data. Which as you can image is useful for much of data science!\n",
    "\n",
    "Then, a kind soul called Wes McKinney decided to make our lives even easier. He created __pandas__, a library built on top of numpy which makes analysing messy, real-world datasets more intuitive. Pandas adds more functionality and a wonderfully useful 2-dimensional data structure known as a DataFrame.\n",
    "\n",
    "Knowing how to use these libraries will make the slog of understanding your data and getting it into a useable state much easier. If you also understand _why_ these libraries matter, your code will be faster, more reuseable and better suited to being deployed into production. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TL;DR : Check if numpy or pandas has a function that does it for you\n",
    "If you don't read any further, that's the key lesson. Here's how you can do it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# give it a go\n",
    "np.lookfor('love')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# you could implement this for another library,\n",
    "# such as pandas, with something like\n",
    "[name for name in dir(pd) if 'max' in name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# think np has a sum method?\n",
    "# let's check\n",
    "np.su*?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# how about pandas?\n",
    "pd.s*?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In general, make extensive use of documentation & stackoverflow, and include numpy and/or pandas in your search."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_______"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Why do we care about numpy?\n",
    "1. Our code is faster\n",
    "3. Our code is (often) more readable\n",
    "2. Our code is (almost always) more intuitive\n",
    "\n",
    "#### For example:  Implementing a simple  [random walk](https://en.wikipedia.org/wiki/Random_walk)\n",
    "i.e. at each step, move either one place forward or one place backward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# python implementation - requires for loop\n",
    "import random\n",
    "\n",
    "def random_walk(n):\n",
    "    '''Randomly walk n steps'''\n",
    "    position = 0\n",
    "    walk = [position]\n",
    "    for i in range(n):\n",
    "        position += random.choice([-1, 1])\n",
    "        walk.append(position)\n",
    "    return walk\n",
    "\n",
    "%timeit random_walk(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# numpy implementation - no for loop, ~100x faster, more readable\n",
    "def random_walk(n):\n",
    "    '''Randomly walk n steps'''\n",
    "    steps = np.random.choice([-1,1], size=n) \n",
    "    return np.cumsum(steps)\n",
    "\n",
    "%timeit random_walk(1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The idea of removing `for` loops in favour of creating and manipulating whole arrays at a time is central to numerical computing in python, and most of what follows focuses on it. You can think of this as moving from thinking in terms of scalars to instead thinking in terms of arrays. Which is also central to TensorFlow - and if you believe the hype, that's the ticket to getting people to react to you like: <img src=http://i0.kym-cdn.com/photos/images/original/000/515/629/9bd.gif alt=\"OMG cat\">\n",
    "\n",
    "But while a particular library can give us some extremely useful tools, it's far from the whole story on writing good clean and clear code, or even fast code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How do I make my code fast?\n",
    "There are two main ways to speed up your computations:\n",
    "-  __move computation or memory allocation outside a `for` loop__\n",
    "-  __compute less, or better__. \n",
    "\n",
    "Python can often be made faster if you don't settle for the first implementation that comes to mind. \"Make use of numpy\" is the theme, but the more general lesson is \"think about the implementation!\"\n",
    "\n",
    "#### For example, how can we most efficiently solve this:\n",
    "> Compute all 4-digit combinations which sum to 10. -- e.g. (0,0,0,10), (1,0,0,9), ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def naive_brute_force():\n",
    "    '''Compute all 4-digit combinations which sum to 10'''\n",
    "    # 11^4 = 14641 iterations & tests\n",
    "    Z = []\n",
    "    for i in range(11):\n",
    "        for j in range(11):\n",
    "            for k in range(11):\n",
    "                for l in range(11):\n",
    "                    if i+j+k+l == 10:\n",
    "                        Z.append((i,j,k,l))\n",
    "    return Z\n",
    "\n",
    "%timeit naive_brute_force()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The final `for` loop and `if` statement are redundant, so we can be more efficent and get an order of magnitude speed-up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def compute_less():\n",
    "    '''Compute all 4-digit combinations which sum to 10'''\n",
    "    Z = []\n",
    "    for a in range(11):\n",
    "        for b in range(11 - a):\n",
    "            for c in range(11 - a - b):\n",
    "                Z.append((a, b, c, (10 - a - b - c)))\n",
    "    return Z\n",
    "\n",
    "%timeit compute_less()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Readability counts**. So for slightly neater code, we might prefer to put this in a list comprehension (which also gains us some negligible speed-up)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def neat_list_comprehension():\n",
    "    '''Compute all 4-digit combinations which sum to 10'''\n",
    "    return [(a, b, c, (10 - a - b - c))\n",
    "            for a in range(11)\n",
    "            for b in range(11 - a)\n",
    "            for c in range(11 - a - b)]\n",
    "\n",
    "%timeit neat_list_comprehension()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Think about the use case.** Here we're doing probably answering a single simple question (\"How many 4-digit combinations sum to 10?\"), so want to be able to call `len` on the list we calculate. \n",
    "\n",
    "But what if we don't need to use values immediately, or if we expected our list to be much, much longer? To take an extreme case - what if we were calculating the Fibonacci sequence? Then we probably just want to be able to iterate through the values, and can create a **generator instead of a list**. This gives a further couple orders of magnitude speed up, because we're not actually creating the values (i.e. it's not doing the same computation as the functions above). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def generator_comprehension():\n",
    "    '''Compute all 4-digit combinations which sum to 10'''\n",
    "    return ((a, b, c, (10 - a - b - c))\n",
    "            for a in range(11)\n",
    "            for b in range(11 - a)\n",
    "            for c in range(11 - a - b))\n",
    "\n",
    "%timeit generator_comprehension()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Aside: Remember generators return an _iterator_ which returns a stream of values (they don't return values themselves, so are more like function definitions). For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# define a trivial generator\n",
    "def generate_ints(n):\n",
    "    for i in range(n):\n",
    "        yield i\n",
    "\n",
    "# create a generator\n",
    "gen = generate_ints(4)\n",
    "gen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# re-run this cell multiple times\n",
    "next(gen)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A view or a copy - what's the difference?\n",
    "Generators might be an example of \"computing less\" or \"computing better\", depending on how you look at it. Another example that fits into a simpler place is the idea of creating views, rather than copies (when views are okay, and that's sometimes a tricky question)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# creating a copy of a big array is nearly as\n",
    "# costly as simple numerical operations on them\n",
    "a = np.zeros(10**6)\n",
    "%timeit a.copy()\n",
    "%timeit a + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Views__ means that the data of both objects is shared. You can create views by selecting a slice of the original array, or also by changing the dtype. I won't talk more about this here, but looks out for 'creates a view' and 'creates a copy' when reading the documentation of functions. And there's more [info here](http://scipy-cookbook.readthedocs.io/items/ViewsVsCopies.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What makes numpy fast?\n",
    "\n",
    "You might wonder how it's possible for an extension to a language, like the numpy extension of python, can make computations faster - how, for example, it can move to an array-first approach. If you're not wondering that - move right on to the actual coding!\n",
    "\n",
    "The key is that a numpy array is stored in a *contiguous block of memory*. This [locality in memory](https://en.wikipedia.org/wiki/Locality_of_reference)\n",
    "allows for __faster accessing and for specialised implementations__ of method, many of which are actually executed in C, not python.\n",
    "\n",
    "In fact, items are (often) stored as C arrays, which are statically typed. Items in a numpy array are *the same data type*, meaning we (often) __avoid the cost of per-element dynamic type checking__.\n",
    "\n",
    "The items in an array can be accessed using an *indexing scheme*. The indexing scheme is by shape and data type -- exactly what is needed in defining a new array.\n",
    "\n",
    "ndarray = block of memory (raw data) + indexing scheme (how to locate an element) + data type descriptor (how to interpret an element)\n",
    "\n",
    "_(The complete story involves a few more complications)_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "new_array = np.arange(12).reshape(4,3).astype(np.int8)\n",
    "print(new_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`new_array` is stored as 12 bytes, one after the other (a contiguous block of memory). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print('new_array has')\n",
    "print('shape:', new_array.shape)\n",
    "print('dimension:', new_array.ndim) # equivalent to len(new_array.shape)\n",
    "print('item size:', new_array.itemsize) # we specified 8-bit integers (so each is 1-byte)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Traversing a numpy array\n",
    "The **strides** of an array tell us how many bytes we have to skip in memory to move to the next position along a certain axis. \n",
    "\n",
    "For example, in our (4, 3) array of 8-bit integers we have to skip 1 byte (1 value) to move to the next column, but 3 bytes (3 values) to get to the same position in the next row. As such, the strides for the `new_array` are (3, 1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "strides = (new_array.shape[1] * new_array.itemsize, new_array.itemsize)\n",
    "assert strides == new_array.strides\n",
    "print(strides)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see this in action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "c = np.array([[1, 2, 3],\n",
    "              [4, 5, 6],\n",
    "              [7, 8, 9]], dtype=np.int16) # note ints are 16-bit == 2-bytes\n",
    "c.data.tobytes()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At which byte does `c[2, 1]` begin?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# what's the stride length for each dimension?\n",
    "print(c.strides)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# get to [2, 1]\n",
    "c.data.tobytes()[6*2 + 2*1] == c[2, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The majority of this notebook provides challenges for you. \n",
    "They come in two parts:\n",
    "1. A series of examples and coding challenges to build your skills in numpy\n",
    "2. A series of problems that require you to [vectorise](https://en.wikipedia.org/wiki/Array_programming) : re-implement functions to apply operations to entire subsets of your data, rather than item by item.\n",
    "\n",
    "The accompanying notebook `Pandas.ipynb` covers\n",
    "1. Querying and merging data : Using pandas as an in-memory database.\n",
    "2. Cleaning and transforming data : Showing off the wonders of pandas.\n",
    "\n",
    "You can also ctrl+f for 'Task' to find all the programming challenges."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Hello Numpy World \n",
    "Let's see what I'm on about. \n",
    "\n",
    "We'll cover:\n",
    "    \n",
    "    i. Creating data arrays\n",
    "    ii. Indexing \n",
    "    iii. Reshaping arrays\n",
    "    iv. Broadcasting scalars and arrays to different sizes\n",
    "    v. Matrix operations\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## i. Creating data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.zeros(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.ones(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.array([1,0,0,1,0]) # note: argument is a list [...]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# evenly spaced\n",
    "np.linspace(0, 1, num=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task: create some data on a log scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "r = np.random.randint(0, 6, size=(4, 3))\n",
    "r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.zeros_like(r)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task: When would `np.zero ` be useful in machine learning. When might we prefer `np.zero_like`?\n",
    "Relatedly, why might over-writing zeros with new values be preferable to just appending new values to an empty list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## actually think. maybe google to find cases where it's used"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Gaussian\n",
    "np.random.randn(4)      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task: Try setting the seed before creating an array with random values. (Generate data from a different distribution. Try to figure out what `np.random.seed` does.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.random.seed(1)  \n",
    "## your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ii. Access data by indexing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a = np.arange(9).reshape(3,3)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a[2,2] # item by index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a[1] # row by index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a[:,2] # column by index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a[1:, :2] # what is this doing?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task: Using a single index, of the form `a[:,:]`, access the 4 corner values of our matrix `a` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task:  Select the even numbers from the (5, 5) array defined below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a = np.arange(25).reshape(5, 5)\n",
    "## your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Indexing_\n",
    "![](../input/pictures/numpy_indexing.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task: return the 2nd, 3rd and 5th item in every other row in `P`, starting with row 0\n",
    "Hint: look at np.ix_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "P = np.random.rand(5, 5)\n",
    "## your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task: Generate a 10 x 3 array of random numbers in range [0,1]. For each row, pick the number closest to 0.5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## your code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task: You're given two matrices of the same shape. Select values from the first if the values in the second are positive. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "first = np.random.randint(10, size=(10,10))\n",
    "second = np.random.randn(100).reshape(10,10) - 0.3\n",
    "## your code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## iii. Reshaping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "z = np.zeros(6)\n",
    "print(z.shape)\n",
    "print(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "z.reshape(len(z), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "z[3] = 1\n",
    "z = z.reshape(3,2)\n",
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "z.itemset((2,1), 8) # set in-place\n",
    "z = z.reshape(2, -1) # unspecified (-1) dimension inferred\n",
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# transpose \n",
    "z.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(z.ravel()) # view\n",
    "print(z.flatten()) # copy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task: Create a 3-dimensional array, then use indexing to return the first dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task: split `arrays` into 3 arrays with shape (10, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "arrays = np.stack([np.random.randn(3, 4)\n",
    "                   for _ in range(10)], axis=0)\n",
    "print(arrays.shape)\n",
    "\n",
    "## your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## iv. Broadcasting\n",
    "On numpy arrays operations, like `+`, `-`, `*`,  are elementwise. It’s possible to do __operations on arrays of different sizes__ when numpy can transform them to be the same size (known as \"broadcasting\")."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.ones(5) * 2 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You could get the same result in python like `[2] * 5` but that's not quite the same operation... \n",
    "#### Task: In plain python, if you have data in a list like `[1, 1, 1, 1, 1]` how would you multiply the values by 2?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "l =  [1, 1, 1, 1, 1]\n",
    "## your pure python code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task: In plain python, if you have data in a list like `[2, 2, 2, 2, 2]` how would you multiply the values elementwise by a second list like `[3, 6, 12, 24, 48]`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Z = np.arange(9).reshape(3,3)\n",
    "Z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Z + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1 was 'broadcast' into the same shape as Z, i.e. `np.ones(shape=(3,3))`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.alltrue(Z + 1 == Z + np.ones((3,3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# let's make the values in a row all the same by\n",
    "# adding this [2, 1, 0] to the corresponding columns\n",
    "this = np.arange(3)[::-1]\n",
    "print(this)\n",
    "Z + this"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task: Create a (10, 9) 2-d array where values on the same row all have the same value\n",
    "hint: look at `np.tile` and `np.repeat` and `np.broadcast_to`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task: Make use of broadcasting to add 3 to first row, 2 to the second row and 1 to the third row of Q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Q = np.arange(9).reshape(3,3)\n",
    "## your single line of code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Broadcasting_\n",
    "![](../input/pictures/numpy_broadcasting.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### v. Matrix operations\n",
    "\n",
    "So far we've always worked with N-dimensional arrays (type `numpy.ndarray`), which can be created with `np.array`. Numpy also has a `np.matrix` method which creates strictly 2-dimensional matrices (with type `numpy.matrixlib.defmatrix.matrix`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.matrix?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "M = np.matrix('1 2; 3 4')\n",
    "N = np.matrix([[4, 3], [2, 1]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Matrices have different behaviour to arrays.\n",
    "\n",
    "For example, remember that operations on arrays are usually elementwise. Which often leads to convenient behaviour, for example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "A = np.array([[1, 2], [3, 4]])\n",
    "A * 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But, some people can find elementwise behaviour unintuitive. For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "B = np.array([[4, 3], [2, 1]])\n",
    "\n",
    "# will return elementwise mutiplication\n",
    "A * B"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When multiplying 2x2 arrays together, one might expect _matrix multiplication_ (i.e. the dot product). This is exactly what you get when multiplying numpy matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "N * M"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For arrays we need to explicitly use `np.dot`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "A.dot(B)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But, different behaviour like this is pretty much the main benefit of using the `matrix` type. It's also the main downside. Writing a program that uses both matrices and arrays makes your life difficult because you have to keep track of what type of object your variables are, lest multiplication (or `ravel` or whatever) returns something you don't expect.\n",
    "\n",
    "In contrast, sticking solely with `ndarrays`, __`arrays` can do everything `matrix` objects can do, and more__, except with slightly different functions/notation. In fact, this means you only need to know one set of functions and there behaviour on arrays.\n",
    "\n",
    "If you are willing to give up the visual appeal of numpy matrix product notation, then numpy arrays are definitely the way to go. \n",
    "\n",
    "**Let's focus on common matrix operations, using arrays**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task: Find a vector `y` such that the dot product of `W` and `y` = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "W = np.arange(1, 10).reshape(3,3).T\n",
    "## your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task: Determine if X is invertible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = np.random.randint(99, size=(12, 12))\n",
    "## your code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task: You want to save a large grey-scale image, 300x300 pixels with values 0.0 to 1.0 (bigger is darker). Fortunately, the image is not very interesting - it's just a black sqare. How would you save the image more efficiently, so that it can easily be recreated? Define an array and save it as `.npy`.\n",
    "Hint: 1. Saving `np.ones((300, 300))` is not sufficiently efficient. 2. Look at `np.save`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task: write a function that takes your saved filename as input and returns your very interesting plain black square (either as an array or plotted)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task: \n",
    "You started saving slightly more interesting images: national flags. But you're still as comitted to decomposing them in ways that allow you to save them more efficiently. To allay worries that they're not being recreated properly: write a function that takes two ndarrays as input and tells us whether or not they recreate a scandinavian flag (as defined below)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sweden = np.array([[6, 6, 3, 6, 6, 6],\n",
    "                   [6, 6, 3, 6, 6, 6],\n",
    "                   [3, 3, 3, 3, 3, 3],\n",
    "                   [6, 6, 3, 6, 6, 6],\n",
    "                   [6, 6, 3, 6, 6, 6]])\n",
    "\n",
    "denmark = np.array([[0, 0, 1, 0, 0, 0],\n",
    "                    [0, 0, 1, 0, 0, 0],\n",
    "                    [1, 1, 1, 1, 1, 1],\n",
    "                    [0, 0, 1, 0, 0, 0],\n",
    "                    [0, 0, 1, 0, 0, 0]])\n",
    "\n",
    "norway = np.array([[0, 1, 2, 1, 0, 0],\n",
    "                   [1, 1, 2, 1, 1, 1],\n",
    "                   [2, 2, 2, 2, 2, 2],\n",
    "                   [1, 1, 2, 1, 1, 1],\n",
    "                   [0, 1, 2, 1, 0, 0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task: Using  `np.linalg.svd`, find and graph the singular values of A and B. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "A = np.random.uniform(0, 1, size=(20, 40))\n",
    "B = np.random.randn(20, 40)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Linear algebra methods can be applied to several matrices at once, if stacked into the same array.\n",
    "\n",
    "For an input array `a`, if `a.shape == (N, M, M)` it is interpreted as a “stack” of `N` matrices, each of size `M-by-M`. Similar specification applies to return values, e.g. `np.det(a).shape == (N,)`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_______"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Vectorising operations\n",
    "Strighting out operations to avoid loops. In other words, let's apply operations to entire subsets of data, rather than item by item."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### Task: Write an `add` function in plain python that takes two lists as input and returns their elementwise sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def add(first, second):\n",
    "    '''Elementwise sum'''\n",
    "    ## your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task: Write an `add` function using numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def vectorised_add(first, second):\n",
    "    '''Elementwise sum'''\n",
    "    ## your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task: Compute the euclidean distance between all points on a grid of evenly spaced values\n",
    "- Create an array of 1000 evenly spaced values\n",
    "- Create a grids of all possible (x, y) values from the array (look at `np.meshgrid`)\n",
    "- Compute a matrix `d` containing euclidean_distance(x, y) for each (x, y) pair\n",
    "\n",
    "To check your answer, we provide code for plotting `d`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## your code here "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "plt.imshow(d, cmap=plt.cm.gray)\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vectorising functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task: Applying this in machine learning \n",
    "In supervised machine learning, we use labelled data to find the parameters of a function that accurately maps the raw data to the corresponding labels. We 'learn' the parameters by quantifying how well our current model is doing and using some optimization criterion to update the parameters in a direction that improves predictions.\n",
    "\n",
    "Therefore, a common machine learning task is minimising a function which quantifies the agreement between our model's predictions and the ground truth \n",
    "(call this function a [_loss function_](https://en.wikipedia.org/wiki/Loss_function) or _cost function_).\n",
    "\n",
    "Of course when training a model, we want to be able to get fast feedback on how well we're doing, so it's important to calculate the loss function efficiently. Below, we give you a dataset of images belonging to 10 categories, a function that maps the raw data to class scores and a (inefficient, non-vectorised) loss function.\n",
    "#### You need to speed the learning up, by implementing a vectorised version of the loss function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Data** : 60,000 tiny images belonging to 10 different categories. _For example:_\n",
    "![](../input/pictures/cifar10.jpeg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# you don't have to read this\n",
    "import pickle\n",
    "def unpickle(file):\n",
    "    '''Unpickle data from binary'''\n",
    "    with open(file, 'rb') as f:\n",
    "        return pickle.load(f, encoding='bytes')\n",
    "\n",
    "def load_cifar10_data(folder='../input/Cifar-10'):\n",
    "    '''Load train and test sets of CIFAR 10 data.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    folder : string, optional (default = 'Cifar-10-data')\n",
    "        Path to folder containing data.\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    X_train : numpy array, shape (50000, 3072)\n",
    "        Matrix of flattened 32x32 pixel RGB images.\n",
    "    y_train : numpy array, shape (50000,)\n",
    "        Vector of corresponding labels for images.\n",
    "    X_test : numpy array, shape (10000, 3072)\n",
    "    y_test : numpy array, shape (10000,)\n",
    "    '''\n",
    "    trainingset = {}\n",
    "    for i in np.arange(1,6):\n",
    "        trainingset[i] = unpickle('{}/data_batch_{}'.format(folder, i))\n",
    "    # 'b' prefix required for bytes literals in python 3\n",
    "    X_train = np.vstack([trainingset[i][b'data'] for i in np.arange(1,6)])\n",
    "    y_train = np.hstack([trainingset[i][b'labels'] for i in np.arange(1,6)])\n",
    "\n",
    "    testset = unpickle('{}/test_batch'.format(folder))\n",
    "    X_test = testset[b'data']\n",
    "    # testset labels are a list. Make np.array for consistency.\n",
    "    y_test = np.array(testset[b'labels'])\n",
    "    \n",
    "    return X_train, y_train, X_test, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Score function** : We'll use a simple linear model $$ s = f(x, W) = Wx $$ (Ignoring the usual bias term $b$. If you wish to include it, extend $W$ to have an extra column and each image vector $x$ with a $1$ that multiplies the new bias column of $W$).\n",
    "    - Specifically, $x$ is an image, so a 1-d array of 32x32x3 = 3072 pixel values\n",
    "    - We want to assign $x$ a score for each of the 10 possible labels, so $s$ will be a vector of length 10, and thus $W$ will have shape (10, 3072)\n",
    "![](../input/pictures/linearClassifier.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def score(x, W): \n",
    "    return np.dot(W, x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Loss function** : We'll use $ L = max(0,-) $ sometimes called the _hinge loss_.\n",
    "    - Specifically the loss for a single image $x_i$ is $$ L_i = \\sum_{j \\neq y_i} max(0, s_j - s_{y_i} + \\Delta ) $$\n",
    "        - $j$ are the 10 possible classes,\n",
    "        - $y_i$ is the correct class for image $x_i$, and\n",
    "        - $s$ is the vector of scores assigned by the score function (so $s_j$ is the score assigned to the $j^{th}$ class)\n",
    "    - i.e. the loss $L_i$ for a single image $x_i$ equals zero when the score function assigns the correct class $y_i$ a score that is at least delta greater than the sore assigned to any other class, for some hyperparameter delta.\n",
    "![](../input/pictures/hingeLoss.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# non-vectorised\n",
    "def L_i(x_i, y_i, W, delta=1.):\n",
    "    '''Calculate hinge loss for single image.\n",
    "    \n",
    "    Very inefficent. Takes only a single \n",
    "    image as input and loops over class.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    x_i : numpy array\n",
    "        flattened input image pixels, shape (N,)\n",
    "    y_i : int\n",
    "        index of the true class label (in Cifar-10\n",
    "        this is the same as the true class label).\n",
    "    W : numpy array\n",
    "        weight matrix, shape (K, N)\n",
    "    delta : float, optional (default = 1.)\n",
    "    '''    \n",
    "    scores = score(x_i, W)\n",
    "    loss_i = 0.0\n",
    "    for j in np.arange(scores.shape[0]):\n",
    "        if j != y_i:\n",
    "            loss_i += max(0, scores[j] - scores[y_i] + delta)\n",
    "    return loss_i"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check the function runs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# hand set a score vector \n",
    "x = np.array([13, -7, 11])\n",
    "W = np.eye(3) # 3x3 identity matrix\n",
    "\n",
    "# arbitrarily say the first entry is the score for the correct class\n",
    "y = 0\n",
    "# since the second entry (-7) is negative, the loss should be 11 - 13 + delta\n",
    "loss = L_i(x, y, W, delta=10.)\n",
    "print('loss =', loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See how fast it is on a proper dataset of 50,000 images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# not going to use the test set\n",
    "X_train, y_train, _, _ = load_cifar10_data()\n",
    "\n",
    "# random weights\n",
    "W = np.random.randn(30720).reshape(10, 3072)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%timeit\n",
    "total_loss = 0\n",
    "for x_i, y_i in zip(X_train, y_train):\n",
    "    total_loss += L_i(x_i, y_i, W)\n",
    "print(total_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task: speed the learning up, by implementing a vectorised version of the loss function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## EXERCISE\n",
    "def L(X, y, W):\n",
    "    '''Calculate hinge loss more efficiently.'''\n",
    "    \n",
    "    #### YOUR \n",
    "    #### CODE\n",
    "    #### HERE\n",
    "    \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hints:\n",
    "- You could first vectorise the calculation of the loss for a single image (which would still require us to loop over the entire training set, but not every pixel). Then, figure out how to modify that function to vectorise the calculation of the loss for an entire training set.\n",
    "\n",
    "\n",
    "- Remember to exclude the score assigned to the correct class when calculating the loss. You're not using a `for` loop, so you're not going to use an `if` statement either... how else can numpy be used to select out an element instead?\n",
    "\n",
    "\n",
    "- Look at the various `max` functions available in numpy.\n",
    "\n",
    "\n",
    "- You might want to rewrite the `score` function\n",
    "\n",
    "Note: we've only given you a small dataset (50,000 32x32px images), which is probably not big enough to see the speed benefits of vectorising. The ImageNet dataset which is standardly used for training and benchmarking image classifiers is more like 15 million higher-quality images.\n",
    "\n",
    "Aside:\n",
    "- Numpy also has a `np.vectorize` method you can investigate (I think it's for tidiness and convenience, rather than speed, but I've not used it yet - please teach me if it's useful)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task: \n",
    "You know that once you actually train your model and learn seemingly good parameters for your score function, you're going to want to benchmark the predictions against another model. \n",
    "\n",
    "You decide to pick the simplest possible model: a k-nearest neighbour classifier, which simply calculates the distance between the input image and all other images, based on elementwise pixel distances, and labels the input with the same class label as the nearest image (or taking a majority vote of the k nearest images).\n",
    "\n",
    "#### Write the predict method for the KNN classifier \n",
    "Again, avoid looping over the pixels (ideally avoid looping over every image too).\n",
    "#### You could also implement a simple distance function (e.g. L1 or L2 norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class KNearestNeighbours(object):\n",
    "    \n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def train(self, X, y):\n",
    "        '''Load the data into memory.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        X : array_like, shape (N, D)\n",
    "            Matrix of N training examples.\n",
    "        \n",
    "        y : array_like, shape (N,)\n",
    "            Vector of N training labels.\n",
    "        '''\n",
    "        self.X_train = np.array(X)\n",
    "        self.y_train = np.array(y)\n",
    "        \n",
    "    def predict(self, X, distance, k=1):\n",
    "        '''Predict class labels for X.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        X : numpy array, shape (M, D)\n",
    "            Matrix of M examples to label.\n",
    "            \n",
    "        distance : function\n",
    "            Method for calculating distance\n",
    "            between Xs and training data.\n",
    "            \n",
    "        k : int, optional (default = 1)\n",
    "            Number of neighbours to consider.            \n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        y_pred : numpy array, shape (M,)\n",
    "            Vector of predicted labels for X.\n",
    "        '''        \n",
    "\n",
    "        ### your\n",
    "        ### code\n",
    "        ### here\n",
    "        \n",
    "        return y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_______"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Whenever you think of writing your own function:\n",
    " - First, check if numpy or pandas can do it for you (in the cases above, we could actually have looked at sklearn or scipy too).\n",
    " - Then, if not, make use of numpy and pandas for writing a vectorised function\n",
    " \n",
    "Caveats:\n",
    "1. Debugging is difficult and inevitable. It's also harder than writing code in the first place. So, if you’re as clever as you can be when you write it, how will you ever debug it? Make use of vectorisation to write faster, cleaner code, not to be a smart arse.\n",
    "2. Maintenance is also inevitable. Which means readability counts. When vecotrising code, that mean:\n",
    "    - If the implementation is hard to explain, it's a bad idea.\n",
    "    - If the implementation is easy to explain, it _may_ be a good idea."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Credit\n",
    "- Some of this notebook edits and builds on resoures found in the open-source book [From Python to Numpy](http://www.labri.fr/perso/nrougier/from-python-to-numpy/)\n",
    "- Other parts make use of the resurces found in [scipy lecture notes](http://www.scipy-lectures.org/)\n",
    "- The problem of vectorising a hinge loss function and implementing KNN is based on [CS231n](http://cs231n.github.io/).\n",
    "- The idea of flags as matrices comes from somewhere in a Gilbert Strang book.\n",
    "- Thanks to Andrew Crozier for suggestions that made major imporovements\n",
    "\n",
    "Any errors and inefficiency in the code were introduce by Nick. Feedback saying which bit were useful and which bits were not to @nick on slack. Genuine rewards (tasty snacks) for people who suggest a new exercise that gets included in v2.0 of this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# little pythonic treat\n",
    "import this"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Copyright © ASI 2017 All rights reserved"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:Python3]",
   "language": "python",
   "name": "conda-env-Python3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
